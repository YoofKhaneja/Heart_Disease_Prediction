{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding_from_Siamese.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoofKhaneja/Heart_Disease_Prediction/blob/master/Codes/Embedding_from_Siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zIgx5eu8uY4",
        "colab_type": "text"
      },
      "source": [
        "# Generate Embeddings using Weights of Pre-Trained Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWnUTIzm9s2p",
        "colab_type": "text"
      },
      "source": [
        "### The weights Siamese network that was trained beforehand are used in a new single network to generate better embeddings of data. These new embeddings will then be used to train a new network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eQV8CYu63od",
        "colab_type": "text"
      },
      "source": [
        "## Importing the basic libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Za4YM2UmvHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4b26a135-70e3-49af-9ad8-5e2f19fd989b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrxV7cT76_05",
        "colab_type": "text"
      },
      "source": [
        "## Random seeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hSY20kUuZQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vQnRJ8x7Fqs",
        "colab_type": "text"
      },
      "source": [
        "## Loading the saved model and creating our new base network from it to generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tl7kJYmnqDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "13d38dc9-a93d-4e81-b33a-e3ee708aa624"
      },
      "source": [
        "from keras import Model\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "save_path_model = 'gdrive/My Drive/Models/siamese_model.h5'\n",
        "\n",
        "trained_model = tf.keras.models.load_model(save_path_model, compile = False)\n",
        "base_model = trained_model.get_layer('model_1')\n",
        "base_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy')\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "D1 (Dense)                   (None, 256)               4096      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "D2 (Dense)                   (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "Embeddings (Dense)           (None, 256)               65792     \n",
            "=================================================================\n",
            "Total params: 135,680\n",
            "Trainable params: 135,680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj1tDUlF7Wfz",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing the weights of each layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjwIYuyoVy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3088
        },
        "outputId": "9a8b5fad-792e-41b9-a543-5c700c9c4f71"
      },
      "source": [
        "names = [weight.name for layer in base_model.layers for weight in layer.weights]\n",
        "weights = base_model.get_weights()\n",
        "\n",
        "for name, weight in zip(names, weights):\n",
        "    print(name, weight)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D1/kernel:0 [[-0.03427828 -0.1166769  -0.18679358 ... -0.13371812  0.041263\n",
            "  -0.00672845]\n",
            " [ 0.17939064  0.03030923  0.26468658 ...  0.06424628 -0.03032227\n",
            "   0.07319709]\n",
            " [-0.1999097  -0.08756134  0.02894405 ... -0.1502114   0.01699038\n",
            "  -0.06084306]\n",
            " ...\n",
            " [-0.31553492  0.00631373 -0.39221194 ... -0.00922348 -0.06669644\n",
            "   0.11098632]\n",
            " [-0.09538467  0.02503878 -0.5253639  ... -0.045489   -0.329623\n",
            "  -0.14117706]\n",
            " [ 0.68699044  0.07068501  0.21337342 ... -0.12301858  0.5711737\n",
            "   0.00327674]]\n",
            "D1/bias:0 [-0.06551323 -0.06177347 -0.01510248 -0.01372928 -0.04592711 -0.01240074\n",
            " -0.09899022  0.04940843 -0.02035042 -0.22662735 -0.05219442 -0.1330062\n",
            " -0.2666434  -0.0418493  -0.16536687 -0.06181517 -0.088353   -0.01001294\n",
            " -0.04381838  0.06454594 -0.0531755  -0.18516235 -0.3974465   0.2787768\n",
            " -0.07996714 -0.02796206  0.11493509  0.02493656 -0.03950033  0.03502818\n",
            "  0.07179437  0.19361389 -0.01018015 -0.05257381  0.00732957  0.07209556\n",
            " -0.06532259  0.13905023 -0.21651517  0.15418166 -0.11474596  0.19473472\n",
            " -0.04092314 -0.03985607  0.05554372 -0.03922937 -0.03412333  0.03209471\n",
            " -0.22835086 -0.00181837 -0.02550578  0.02093167 -0.15691133 -0.08375029\n",
            "  0.01979948 -0.05384767 -0.04843197 -0.12624258 -0.04899726  0.26313272\n",
            " -0.00574821  0.09940878 -0.02417007 -0.11358354 -0.17244971 -0.01686739\n",
            "  0.02572415  0.04183653 -0.10167605  0.20367117 -0.06118727 -0.01930418\n",
            " -0.03004828 -0.04759321 -0.18740171 -0.04471998  0.14668001 -0.10216927\n",
            " -0.13776268 -0.01442959 -0.03948327 -0.27792066 -0.14299148  0.12552877\n",
            "  0.03687782  0.03274961 -0.07479466 -0.11261242 -0.01504443 -0.03336669\n",
            "  0.08808629  0.2513048  -0.2802387  -0.17224915 -0.07016223 -0.06559196\n",
            " -0.04802473 -0.04784629  0.15422502 -0.15299642  0.         -0.01201938\n",
            "  0.02323293 -0.05913371  0.02564679  0.00259461 -0.01790223  0.162774\n",
            "  0.0991355   0.11822339  0.20504247  0.18622807 -0.00921973 -0.06905443\n",
            " -0.02140085 -0.04183554 -0.04606657 -0.37827387 -0.432902   -0.13997293\n",
            "  0.12799306 -0.05697725 -0.09853884 -0.04977333 -0.06653712  0.\n",
            " -0.09633535  0.04710271 -0.00182513 -0.06196337 -0.02203292  0.\n",
            " -0.06368132  0.01273054 -0.04450701 -0.03276015  0.10182069 -0.00541355\n",
            " -0.09022547 -0.1308043  -0.02665309 -0.08714805 -0.04496048 -0.09936977\n",
            " -0.08791077  0.16625816 -0.08837879 -0.05513554  0.13622221  0.01036993\n",
            "  0.05976644  0.16548449 -0.05732305 -0.0494886  -0.07490572 -0.10409129\n",
            " -0.02601384 -0.00789756  0.22330128 -0.16623695 -0.00784752 -0.02819767\n",
            "  0.09649348 -0.10128256 -0.03278745 -0.2028455   0.134481   -0.12632965\n",
            " -0.01668981  0.10050485 -0.00657521  0.11465915 -0.02939206  0.32917017\n",
            "  0.04711951 -0.11698413 -0.04943985 -0.02148788  0.26317886 -0.3502542\n",
            " -0.02047856 -0.05057251  0.05687751  0.04304538  0.11229215  0.10959385\n",
            " -0.04303584 -0.14256254 -0.01843546 -0.2549536  -0.08747083 -0.01618138\n",
            " -0.09825023 -0.01589228 -0.01038347 -0.05217479 -0.21639842 -0.0848074\n",
            "  0.08330236 -0.04405574 -0.05414198 -0.06146659  0.02667576 -0.03032937\n",
            " -0.00187596  0.2118531  -0.29667726 -0.04517598  0.15277502 -0.04981587\n",
            " -0.05305574 -0.0492312   0.00512573 -0.04085163 -0.04448944 -0.01991776\n",
            " -0.07891732 -0.01739601 -0.3959244   0.01988869 -0.2718249  -0.14532782\n",
            " -0.03290832  0.28572315 -0.03668844  0.24660458 -0.01177119 -0.03625735\n",
            " -0.07032975 -0.060736    0.05275392 -0.17505352  0.13980983 -0.0358423\n",
            " -0.12702037 -0.0355695  -0.10326926 -0.01645935 -0.06558685 -0.06354436\n",
            " -0.14345998  0.19980462 -0.0753153   0.06508008  0.08463714  0.01560994\n",
            " -0.02269981 -0.05096393 -0.02423185  0.07890722  0.2382707  -0.03107603\n",
            " -0.03339702 -0.03634829 -0.11723034 -0.02805035]\n",
            "D2/kernel:0 [[-0.47603756 -0.10277832 -0.01469852 ... -0.07407469  0.0779409\n",
            "   0.14039241]\n",
            " [-0.04458429  0.03495047  0.04581307 ...  0.05617812  0.06972697\n",
            "  -0.08857056]\n",
            " [-0.47148463 -0.4740403   0.17778741 ... -0.24624921 -0.0588781\n",
            "   0.06198739]\n",
            " ...\n",
            " [-0.05339217 -0.00852655 -0.09415435 ... -0.07445317 -0.06045285\n",
            "   0.10587184]\n",
            " [ 0.01311144 -0.32303575  0.46610743 ...  0.37629476 -1.3834947\n",
            "  -0.28029692]\n",
            " [ 0.01067     0.08369277  0.07722275 ...  0.0998925   0.07659413\n",
            "   0.01321147]]\n",
            "D2/bias:0 [ 4.77352506e-03 -2.71629356e-02  4.85058688e-02 -2.47060861e-02\n",
            " -2.65477687e-01 -2.39359364e-02 -6.05118498e-02 -1.65914893e-01\n",
            " -2.03492772e-02 -3.40484828e-02 -3.80370915e-02  4.41315435e-02\n",
            "  2.11399924e-02 -2.34595880e-01  4.88063879e-02 -9.03901979e-02\n",
            " -1.11311805e-02 -5.67760281e-02  2.05374397e-02 -8.81576315e-02\n",
            " -4.25948620e-01 -1.33080631e-01 -5.90151921e-02 -1.42870292e-01\n",
            " -3.24262977e-01 -9.06613320e-02 -1.34208659e-02  2.92194844e-03\n",
            " -1.41903326e-01 -1.80695906e-01 -7.95725361e-02 -1.11419663e-01\n",
            " -4.36003245e-02 -2.24076360e-02 -8.74667317e-02 -1.30778300e-02\n",
            " -8.08883309e-02  2.08999985e-03 -2.25222245e-01  1.62848793e-02\n",
            "  1.59101132e-02 -3.21960263e-02 -1.35145672e-02  5.46719544e-02\n",
            " -9.15525556e-02 -4.81103510e-02 -5.90375066e-02  1.53737301e-02\n",
            "  2.08666623e-02 -3.38962525e-02  2.52989270e-02  9.23899096e-03\n",
            " -7.66996592e-02 -2.00538933e-01  1.66653786e-02 -9.93194357e-02\n",
            " -1.16010429e-02 -1.32969916e-01 -9.08382013e-02 -7.90189728e-02\n",
            " -1.02231521e-02  5.92901930e-03  1.46141164e-02 -7.36601651e-02\n",
            " -4.26819101e-02 -1.77386090e-01 -2.46076304e-02 -3.78863933e-03\n",
            " -5.13562560e-02  2.23872326e-02 -4.76168655e-03 -1.47392983e-02\n",
            " -2.49877408e-01 -6.36066645e-02  2.11887136e-02 -2.87598997e-01\n",
            " -2.01915726e-02 -2.45842934e-02 -1.04657449e-01 -1.28441798e-02\n",
            " -7.13632554e-02  1.41589306e-02 -4.96542156e-02  2.73961034e-02\n",
            " -1.33982925e-02 -1.18672386e-01 -1.70255855e-01  3.93469585e-03\n",
            " -2.32833195e-02 -1.25033796e-01 -8.66063237e-02 -2.89097935e-01\n",
            " -2.69914046e-02 -4.31704968e-02  1.50775639e-02 -1.28760738e-02\n",
            " -6.26552626e-02 -1.06440805e-01  3.78715880e-02  5.07577471e-02\n",
            "  2.35609058e-02 -6.78200275e-02 -2.58892663e-02 -7.84698054e-02\n",
            " -1.57794505e-01 -4.42062952e-02  2.74464779e-04 -2.79281110e-01\n",
            " -2.57383697e-02 -3.78337018e-02 -1.97872490e-01  8.94614607e-02\n",
            " -7.74484575e-02 -4.53280583e-02  6.27897587e-03 -3.85520160e-02\n",
            " -4.88880612e-02 -6.13727495e-02 -1.36166826e-01  7.69090140e-03\n",
            " -5.75765930e-02  1.28260795e-02 -8.14501941e-02  1.45268673e-03\n",
            "  8.74181092e-03 -1.50045631e-02 -7.47340266e-03 -1.02136888e-01\n",
            " -1.58550188e-01 -7.34361932e-02  1.81516185e-02 -2.48049926e-02\n",
            " -1.78913832e-01 -2.21225381e-01 -2.18633413e-02 -2.19641849e-01\n",
            " -1.09071173e-01 -5.38587235e-02 -7.90603384e-02 -1.29825264e-01\n",
            " -4.63162027e-02 -7.92349577e-02 -1.41634151e-01  4.19545546e-02\n",
            " -4.10841018e-01 -6.91844821e-01 -4.17093337e-02  1.02490643e-02\n",
            " -8.14704001e-02  3.17404605e-02 -2.48122722e-01 -6.97662979e-02\n",
            " -2.90248543e-01 -8.05806518e-02 -3.24410051e-02 -1.06249437e-01\n",
            " -4.12750989e-02  8.12195765e-04 -5.77553324e-02 -4.03382592e-02\n",
            " -1.22442849e-01 -1.88410103e-01 -9.88159776e-02  1.13245593e-02\n",
            " -1.36166140e-02 -4.41116355e-02 -6.40491024e-02 -4.43898104e-02\n",
            " -8.43359306e-02 -3.38320062e-02  6.65024593e-02 -1.89188775e-02\n",
            "  3.83624621e-02 -7.18346164e-02 -7.21893236e-02  5.96738197e-02\n",
            " -7.86477998e-02 -1.69876307e-01  2.28829607e-02 -1.36172771e-01\n",
            " -3.00241411e-02 -1.50000593e-02 -2.28532135e-01 -1.88732911e-02\n",
            "  9.05721169e-03 -1.47430569e-01 -3.93842645e-02 -3.04666579e-01\n",
            " -2.52897710e-01 -7.48807043e-02 -2.81886280e-01 -8.58938769e-02\n",
            "  3.72618549e-02 -5.45725152e-02 -1.02309264e-01  1.76801290e-02\n",
            " -1.81952417e-02  4.18723933e-03 -1.60227060e-01 -4.87218201e-02\n",
            " -1.06919825e-01 -2.33838148e-02 -5.16322907e-03 -3.00518423e-01\n",
            "  9.38577019e-03 -1.67023633e-02  2.97778603e-02 -8.64772946e-02\n",
            "  5.97093217e-02 -1.56178132e-01 -5.82160875e-02 -9.03030336e-02\n",
            "  3.45836133e-02  2.04458795e-02 -4.76383902e-02 -2.03105018e-01\n",
            " -1.27269730e-01  2.72306949e-02  3.64261009e-02 -8.18968564e-02\n",
            " -2.14053132e-02 -8.47779661e-02 -2.26569951e-01 -7.22105652e-02\n",
            " -2.59129345e-01 -8.66912529e-02 -7.37674907e-02 -6.09518103e-02\n",
            " -8.62187147e-02 -1.65813044e-01 -6.44586682e-02 -4.69764993e-02\n",
            "  6.43362291e-03 -8.00681412e-02 -7.75981918e-02 -7.86048025e-02\n",
            "  2.29719225e-02 -8.60697478e-02 -2.73854673e-01  3.80981937e-02\n",
            " -1.81451929e-03  6.83119055e-03 -1.88866526e-01 -9.69631970e-02\n",
            " -1.84059605e-01  1.46817379e-02 -8.04259181e-02  5.60026169e-02\n",
            "  4.55865003e-02  2.05438547e-02 -4.79460731e-02 -2.19315514e-02\n",
            " -6.71139359e-02  4.30932157e-02  6.05649501e-03 -1.27448784e-02]\n",
            "Embeddings/kernel:0 [[-0.42665341 -0.06101782 -0.14334199 ... -0.13991424  0.010264\n",
            "  -0.16449848]\n",
            " [ 0.12348584 -0.19267927 -0.03127003 ... -0.07199323  0.02751147\n",
            "   0.04219598]\n",
            " [ 0.01403798  0.06859411 -0.1449517  ...  0.05165699 -0.07398673\n",
            "   0.00362745]\n",
            " ...\n",
            " [ 0.3866885  -0.13226205 -0.05470705 ...  0.03376762 -0.01355777\n",
            "   0.16239594]\n",
            " [ 0.03215593 -0.04313272 -0.2866833  ...  0.01319574 -0.0989055\n",
            "   0.01377309]\n",
            " [ 0.03261219 -0.26074865 -0.02567706 ... -0.02617455 -0.07875935\n",
            "   0.0075406 ]]\n",
            "Embeddings/bias:0 [ 0.14794292 -0.07293249 -0.05581836 -0.05016438 -0.06602471 -0.08513767\n",
            " -0.07131322 -0.1140342  -0.01936819  0.13162708 -0.09995627 -0.08829645\n",
            " -0.09273436 -0.05188012  0.0761756  -0.09705357 -0.10018421 -0.0994353\n",
            " -0.10815345 -0.07827649 -0.10484478 -0.06188193 -0.06397906 -0.07502336\n",
            "  0.21227805 -0.03391584 -0.09924111 -0.11543752 -0.04833538  0.05604136\n",
            "  0.08075777 -0.06457414 -0.09787838  0.08274339 -0.09681831 -0.07694172\n",
            " -0.09483249  0.04527159 -0.09655023 -0.09893541 -0.109948    0.03535537\n",
            " -0.03123368 -0.10376594 -0.077684   -0.0961377  -0.10181193 -0.09029743\n",
            " -0.09904315  0.14063594  0.07575819  0.07610319  0.49575084  0.15523182\n",
            " -0.0983884  -0.0612955  -0.09416533 -0.10349067 -0.09337703  0.03325083\n",
            "  0.09931152 -0.12556817 -0.08298648 -0.06213836 -0.08196145 -0.0849556\n",
            " -0.08811175 -0.09224114 -0.08008462 -0.1177102  -0.11716209 -0.13454321\n",
            " -0.08754181 -0.09271392 -0.09019059 -0.09622769 -0.05382267 -0.03851755\n",
            "  0.22344537 -0.11858088 -0.08144508 -0.09388512 -0.07567526 -0.09434468\n",
            " -0.04491896 -0.13409449  0.04018646 -0.10170636 -0.0643238   0.149826\n",
            " -0.06235546 -0.04342462 -0.05402197 -0.08402795 -0.10781451 -0.08209222\n",
            "  0.01477691  0.06513678 -0.09558275 -0.06561095 -0.10360576 -0.0909674\n",
            " -0.10918196 -0.10186728 -0.1417003  -0.09323192 -0.09619243 -0.09963964\n",
            " -0.08083066 -0.094067   -0.08497082  0.09553505 -0.09974868 -0.05132422\n",
            " -0.12693793 -0.09126721 -0.0993906  -0.04849966 -0.0786669  -0.09188408\n",
            " -0.06248289 -0.10015824 -0.09192653 -0.07490978 -0.14558615 -0.09342308\n",
            " -0.09763789 -0.08992366  0.12734698 -0.07998105 -0.05925414  0.10544293\n",
            " -0.09497725 -0.11165041 -0.0985117   0.09688035 -0.09619025 -0.10267993\n",
            " -0.13012598 -0.09112497 -0.09908748 -0.10045791 -0.10791894 -0.10725108\n",
            " -0.07341608 -0.04664034 -0.07514177 -0.06746212 -0.10412259 -0.10727353\n",
            " -0.10050011 -0.07796894 -0.03156037  0.05181076 -0.07662073 -0.10477713\n",
            " -0.08778515 -0.05627216 -0.06867653 -0.09575069 -0.08179597 -0.09046683\n",
            " -0.10045391 -0.05865841 -0.05895634 -0.11043926 -0.05337603 -0.09882534\n",
            "  0.04509564  0.11127569 -0.1020707  -0.08901644 -0.09476029 -0.0757017\n",
            "  0.10140894 -0.06183598 -0.10154627 -0.08279019 -0.05851236 -0.08974443\n",
            "  0.09246048 -0.03430206 -0.11949483 -0.10285737 -0.08323404 -0.09676442\n",
            " -0.0943868  -0.0879793  -0.09871164 -0.09490184  0.05739699 -0.06636803\n",
            " -0.06392495 -0.11380846 -0.09865446  0.12103669 -0.08886442 -0.11860777\n",
            " -0.09454089 -0.10134707 -0.09313225 -0.09252295 -0.09827802 -0.07071222\n",
            " -0.08265891 -0.08010022 -0.05773822 -0.1109807  -0.08084499  0.09410117\n",
            "  0.0892015  -0.1095406   0.04449953  0.05462756 -0.13085034  0.08240154\n",
            " -0.09385233 -0.09774667 -0.05571476 -0.06188298 -0.09629349 -0.01908263\n",
            " -0.08633972  0.03557812  0.07575057 -0.05578505 -0.11671841 -0.10320121\n",
            " -0.12582679 -0.09957533 -0.10169026  0.0507986  -0.08597929 -0.04224934\n",
            " -0.07995622 -0.10762128 -0.05890534  0.05898225 -0.0958212  -0.10715427\n",
            " -0.11965803 -0.07908302 -0.07728509 -0.10149214  0.08756679 -0.06045486\n",
            " -0.11108923 -0.12760925 -0.09613274 -0.10232203 -0.09894971 -0.09859142\n",
            "  0.27231348 -0.0978968  -0.09897905  0.05771265]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKmzV4YP7jjd",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFipRzlobsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "5256fea6-d04c-4d8a-aaa0-fdede92c1d88"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/YoofKhaneja/Heart_Disease_Prediction/master/Codes/framingham.csv'\n",
        "hd = pd.read_csv(url)\n",
        "\n",
        "import random\n",
        "from fancyimpute import IterativeImputer\n",
        "\n",
        "hd.BPMeds = hd.BPMeds.fillna(0)\n",
        "edu = [1, 2, 3, 4]\n",
        "c = 0\n",
        "for i in range(len(hd.education)):\n",
        "    if hd.education[i] not in edu:\n",
        "        t = random.randint(1, 4)\n",
        "        hd.education[i] = t\n",
        "hdi = pd.DataFrame(IterativeImputer().fit_transform(hd))\n",
        "hdi.columns = hd.columns\n",
        "\n",
        "print(hdi.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "male               0\n",
            "age                0\n",
            "education          0\n",
            "currentSmoker      0\n",
            "cigsPerDay         0\n",
            "BPMeds             0\n",
            "prevalentStroke    0\n",
            "prevalentHyp       0\n",
            "diabetes           0\n",
            "totChol            0\n",
            "sysBP              0\n",
            "diaBP              0\n",
            "BMI                0\n",
            "heartRate          0\n",
            "glucose            0\n",
            "TenYearCHD         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCPCI3T1piID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hd_ = hdi.copy(deep = True)\n",
        "hd_['age'] = pd.cut(hd_['age'], \n",
        "                    5, \n",
        "                    labels = [1, 2, 3, 4, 5])\n",
        "hd_['cigsPerDay'] = pd.cut(hd_['cigsPerDay'], \n",
        "                           6, \n",
        "                           labels = [1, 2, 3, 4, 5, 6])\n",
        "hd_['totChol'] = pd.cut(hd_['totChol'], \n",
        "                        13, \n",
        "                        labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
        "hd_['sysBP'] = pd.cut(hd_['sysBP'], \n",
        "                      10, \n",
        "                      labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "hd_['diaBP'] = pd.cut(hd_['diaBP'], \n",
        "                      8, \n",
        "                      labels = [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "hd_['BMI'] = pd.cut(hd_['BMI'], \n",
        "                    10, \n",
        "                    labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "hd_['heartRate'] = pd.cut(hd_['heartRate'], \n",
        "                          8, \n",
        "                          labels = [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "hd_['glucose'] = pd.cut(hd_['glucose'], \n",
        "                        15, \n",
        "                        labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n",
        "\n",
        "hd_['age'] = hd_['age'].apply(lambda x: round(x*0.2, 2))\n",
        "hd_['education'] = hd_['education'].apply(lambda x: round(x*0.25, 2))\n",
        "hd_['cigsPerDay'] = hd_['cigsPerDay'].apply(lambda x: round(x*0.16, 2))\n",
        "hd_['totChol'] = hd_['totChol'].apply(lambda x: round(x*0.077, 2))\n",
        "hd_['sysBP'] = hd_['sysBP'].apply(lambda x: round(x*0.1, 2))\n",
        "hd_['diaBP'] = hd_['diaBP'].apply(lambda x: round(x*0.125, 2))\n",
        "hd_['BMI'] = hd_['BMI'].apply(lambda x: round(x*0.1, 2))\n",
        "hd_['heartRate'] = hd_['heartRate'].apply(lambda x: round(x*0.125, 2))\n",
        "hd_['glucose'] = hd_['glucose'].apply(lambda x: round(x*0.067, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIrCHHJ27pDI",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the data into attributes and labels to generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPxw0Brlpv31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = hd_.iloc[:, :-1]\n",
        "y = hd_.iloc[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YAukyQa71Tx",
        "colab_type": "text"
      },
      "source": [
        "## Generating the new embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz6P-UHhqGWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = base_model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lObwsnCrrDpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp_rUEhDqN8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "68b8360b-876b-4e58-e148-ecf4127e8ac0"
      },
      "source": [
        "x[0]   # Classified as 0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.16824104, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1498962 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.08665089,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24406105,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.06360546,\n",
              "       0.09187763, 0.        , 0.        , 0.09382174, 0.        ,\n",
              "       0.        , 0.        , 0.05123469, 0.        , 0.        ,\n",
              "       0.        , 0.04008992, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.16099757,\n",
              "       0.08590575, 0.08625396, 0.58352333, 0.17722318, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03762483,\n",
              "       0.11253206, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.25635898, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.04550853, 0.        , 0.        , 0.17137446,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.01638877, 0.07369784, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.10820333, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.14478792, 0.        ,\n",
              "       0.        , 0.11975701, 0.        , 0.        , 0.        ,\n",
              "       0.10949814, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.05866743, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.05127451, 0.12613423,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.11473055,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.10557956, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.06508744, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.13727228, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.10645475,\n",
              "       0.10094626, 0.        , 0.05024742, 0.06190657, 0.        ,\n",
              "       0.09344577, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.04041442, 0.08624592,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.05754493, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.05368838, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.09929505,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.3124635 , 0.        , 0.        ,\n",
              "       0.06542294], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAY6_xd2qPAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "eaf31515-6765-40ac-aa47-e69efb29b3e0"
      },
      "source": [
        "x[6]   # Classified as 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.06776211, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuBNPLey74_m",
        "colab_type": "text"
      },
      "source": [
        "## Calculating euclidean distance to see how good the new embeddings are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncpYIg-mrgnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a92d5917-2e95-43c1-a4ca-aa37a8242ddd"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "a = x[0] #0\n",
        "b = x[32] #1\n",
        "c = x[1] #0\n",
        "d = x[33] #1\n",
        "dst00 = distance.euclidean(a, c)\n",
        "dst01 = distance.euclidean(a, b)\n",
        "dst11 = distance.euclidean(b, d)\n",
        "print([dst00, dst01, dst11])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.025290578603744507, 0.9808838367462158, 0.0010116957128047943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToVE7sgwLpaY",
        "colab_type": "text"
      },
      "source": [
        "## Using a simple, single-layered neural network to evaluate the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emc-2-x8H47x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "simple_classifier  = Sequential()\n",
        "simple_classifier.add(Dense(1, input_dim = 256, activation = 'sigmoid'))\n",
        "simple_classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vTQqlnlJsA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits = 1, \n",
        "                             test_size = 0.2, \n",
        "                             random_state = 1)\n",
        "attrib = np.array(x)\n",
        "lab = np.array(y)\n",
        "for train_index, test_index in sss.split(x, y):\n",
        "    x_train, x_test = attrib[train_index], attrib[test_index]\n",
        "    y_train, y_test = lab[train_index], lab[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp3opSm2KFqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = simple_classifier.predict(x_test)\n",
        "preds = (preds <= 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjDtKH06L1cb",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation and results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0R6YmhuKfOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ae32acf8-835d-48e2-c99f-f5d1879f2c77"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "conf_matrix = pd.DataFrame(data = cm, \n",
        "                           columns = ['Predicted: 0', 'Predicted: 1'], \n",
        "                           index = ['Actual:0', 'Actual:1'])\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, preds))\n",
        "conf_matrix"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9752358490566038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted: 0</th>\n",
              "      <th>Predicted: 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual:0</th>\n",
              "      <td>707</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual:1</th>\n",
              "      <td>9</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted: 0  Predicted: 1\n",
              "Actual:0           707            12\n",
              "Actual:1             9           120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbIpQNEtKj-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b33306c2-0b39-4eb2-fad4-83b7e8800a92"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, preds, labels = [0, 1]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       719\n",
            "           1       0.91      0.93      0.92       129\n",
            "\n",
            "    accuracy                           0.98       848\n",
            "   macro avg       0.95      0.96      0.95       848\n",
            "weighted avg       0.98      0.98      0.98       848\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}